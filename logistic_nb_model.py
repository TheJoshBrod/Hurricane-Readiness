# -*- coding: utf-8 -*-
"""11-12.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xTr2fHaVl4L20hwc77dazWqKW95lRV9K
"""

from sklearn.datasets import load_iris

iris = load_iris()

import torch
from torch import tensor

X = tensor(iris.data, dtype=torch.float)
y = tensor(iris.target, dtype=torch.float)
y = (y >= 1) * 1.

from torch import sigmoid

def log_loss(h,y):
  L = -y * torch.log(h) - (1-y) * torch.log(1-h)
  J = L.mean()
  return J

from torch.nn import Module, Parameter
from torch.distributions.normal import Normal

class Logistic (Module):

  def __init__ (self):
    Module.__init__(self)
    self.w = Parameter(Normal(0., 0.1).sample((4,)).requires_grad_())
    self.b = Parameter(tensor(0., dtype = torch.float).requires_grad_())

  def forward (self, X):
    z = X @ self.w + self.b
    h = sigmoid(z)
    return h

model = Logistic()

model(X)

J = log_loss(model(X), y)
J

model.w

model.b

list(model.parameters())

dict(model.named_parameters())

model.w.data

model.w

J.backward()

model.w.grad

model.b.grad

from torch.optim import SGD
sgd = SGD(model.parameters(), lr = 0.01)

model.w.data - 0.01 * model.w.grad

model.b

model.w

sgd.step()

model.w

model.b

model.w.data

model.w.grad

model.zero_grad()

model.w.grad

model.b.grad

def accuracy(h,y):
  yhat = floor(h + 0.5)
  return ((yhat == y) * 1.).mean()

def step (model, X, y, lossf, optz):
  h = model(X)
  J = lossf(h, y)
  print("J: ", J, "acc: ", accuracy(h,y))
  J.backward()
  optz.step()
  model.zero_grad()

step(model, X, y, log_loss, sgd)

step(model, X, y, log_loss, sgd)

model.w

h = model(X)
h

from torch import floor
floor(h + 0.5)



accuracy(h,y)

def train (X, y, stepsize, nepochs):
  model = Logistic()
  sgd = SGD(model.parameters(), lr=stepsize)
  for _ in range(nepochs):
    step(model, X, y, log_loss, sgd)
  return model

train(X, y, 0.001, 1000)

model = Logistic()
sgd = SGD(model.parameters(), lr=0.001)
step(model, X, y, log_loss, sgd)

step(model, X, y, log_loss, sgd)